# Jarvis

This has been discussed like a GAJILLION times but just listen to me. Its a LLM at the core, an LLM Agent to be specific. Integrated among all the various Stark-Tech that Tony Stank(deal with it) has. Its an integration of IOT and LLMs at its core.

My curiosity was in the server size and the GPU size it would require to function that well. Gosh even the SOTA LLMs nowadays take up like GIGS and GIGS of space. Now imagine that across all those suits. The GPUs would melt.

Soon we will achieve a 5 Trillion Parameter model, but, is vertical scaling the only way? Perhaps a new architecture would be found soon.

Only time will tell.....
